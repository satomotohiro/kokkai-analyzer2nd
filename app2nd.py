import streamlit as st
import requests
import datetime
import google.generativeai as genai
import os
from dotenv import load_dotenv
import pandas as pd

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model = genai.GenerativeModel("models/gemini-1.5-flash")

# CSVèª­ã¿è¾¼ã¿ï¼ˆã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°å¯¾ç­–ï¼‰
try:
    politicians_df = pd.read_csv("politicians.csv", encoding="utf-8")
except UnicodeDecodeError:
    politicians_df = pd.read_csv("politicians.csv", encoding="shift_jis")

# æ•´å½¢
def normalize_name(name):
    return name.replace("ã€€", "").replace(" ", "") if name else ""

politicians_df["name"] = politicians_df["name"].apply(normalize_name)

# ä¸»è¦æ”¿å…šé †æŒ‡å®š
main_party_order = ["è‡ªç”±æ°‘ä¸»å…š", "ç«‹æ†²æ°‘ä¸»å…š", "å›½æ°‘æ°‘ä¸»å…š", "æ—¥æœ¬ç¶­æ–°ã®ä¼š", "å…¬æ˜Žå…š", "å…±ç”£å…š", "ã‚Œã„ã‚æ–°é¸çµ„", "ç¤¾æ°‘å…š", "ç„¡æ‰€å±ž"]
def party_sort_key(p):
    return main_party_order.index(p) if p in main_party_order else 999

party_names = sorted(politicians_df["party"].dropna().unique(), key=party_sort_key)
politician_names = sorted(politicians_df["name"].unique())

# UIãƒ˜ãƒƒãƒ€ãƒ¼
st.title("ðŸ’¡ å›½ä¼šè­°å“¡ã®ç™ºè¨€åˆ†æž by ç”ŸæˆAI")
st.markdown("è­°äº‹éŒ²ã‹ã‚‰è©²å½“ç™ºè¨€ã‚’AIã§åˆ†æžã—ã€æ”¿æ²»å®¶ã‚„æ”¿å…šã®æ€æƒ³å‚¾å‘ã‚’å¯è¦–åŒ–ã—ã¾ã™ã€‚")

# æ¤œç´¢æ¡ä»¶
st.markdown("### ðŸŽ¯ æ¤œç´¢æ¡ä»¶ã‚’è¨­å®š")

selected_party = st.selectbox("ðŸ›ï¸ æ”¿å…šã‚’é¸æŠž", ["æŒ‡å®šã—ãªã„"] + party_names)

# æ”¿å…šã«å¿œã˜ã¦è­°å“¡å€™è£œã‚’çµžã‚‹
if selected_party != "æŒ‡å®šã—ãªã„":
    filtered_df = politicians_df[politicians_df["party"] == selected_party]
    filtered_names = sorted(filtered_df["name"].unique())
else:
    filtered_names = politician_names

selected_politician_input = st.selectbox(
    "ðŸ‘¤ å›½ä¼šè­°å“¡ã‚’é¸æŠžã¾ãŸã¯å…¥åŠ›ï¼ˆä¾‹ï¼šæ²³é‡Žå¤ªéƒŽï¼‰",
    ["æŒ‡å®šã—ãªã„"] + filtered_names,
    index=0
)

# è‡ªå‹•æ”¿å…šè£œå®Œ
if selected_politician_input != "æŒ‡å®šã—ãªã„":
    matched_row = politicians_df[politicians_df["name"] == normalize_name(selected_politician_input)]
    if not matched_row.empty:
        detected_party = matched_row["party"].values[0]
        if selected_party == "æŒ‡å®šã—ãªã„":
            st.info(f"ðŸ§¾ æ‰€å±žæ”¿å…šã‚’è‡ªå‹•è£œå®Œï¼š**{detected_party}**")
            selected_party = detected_party

keyword = st.text_input("ðŸ—ï¸ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›ï¼ˆä¾‹ï¼šæ¶ˆè²»ç¨Žï¼‰")

# æ—¥ä»˜æŒ‡å®š
today = datetime.date.today()
five_years_ago = today.replace(year=today.year - 5)
from_date = st.date_input("é–‹å§‹æ—¥", value=five_years_ago)
to_date = st.date_input("çµ‚äº†æ—¥", value=today)

if st.button("ðŸ“¡ æ¤œç´¢ã—ã¦åˆ†æž"):
    st.info("æ¤œç´¢ä¸­...")

    speaker = normalize_name(selected_politician_input)

    if speaker != "æŒ‡å®šã—ãªã„":
        speakers_to_search = [speaker]
    elif selected_party != "æŒ‡å®šã—ãªã„":
        party_members = politicians_df[politicians_df["party"] == selected_party]
        influential_members = party_members[party_members["position"].notna()] if "position" in party_members else party_members
        if influential_members.empty:
            influential_members = party_members
        speakers_to_search = influential_members["name"].tolist()[:5]
    else:
        st.warning("è­°å“¡ã¾ãŸã¯æ”¿å…šã‚’é¸æŠžã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    all_speeches = []
    base_url = "https://kokkai.ndl.go.jp/api/speech"

    for name in speakers_to_search:
        params = {
            "speaker": name,
            "any": keyword,
            "from": from_date.strftime("%Y-%m-%d"),
            "until": to_date.strftime("%Y-%m-%d"),
            "recordPacking": "json",
            "maximumRecords": 5,
            "startRecord": 1,
        }

        with st.spinner(f"{name} ã®ç™ºè¨€ã‚’å–å¾—ä¸­..."):
            try:
                response = requests.get(base_url, params=params)
                if response.status_code == 200:
                    data = response.json()
                    speeches = data.get("speechRecord", [])
                    all_speeches.extend(speeches)
            except Exception as e:
                st.error(f"{name} ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    if not all_speeches:
        st.warning("è©²å½“ã™ã‚‹ç™ºè¨€ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
        st.stop()

    combined_text = "\n\n".join([f"{s['speaker']}ï¼ˆ{s['date']}ï¼‰: {s['speech']}" for s in all_speeches])
    prompt = f"ä»¥ä¸‹ã¯æ—¥æœ¬ã®å›½ä¼šã§ã®ç™ºè¨€ã®æŠœç²‹ã§ã™ã€‚ã“ã®æ”¿æ²»å®¶ãŸã¡ï¼ˆæ”¿å…š: {selected_party if selected_party != 'æŒ‡å®šã—ãªã„' else 'ä¸æ˜Ž'}ï¼‰ãŒã€Œ{keyword}ã€ã«é–¢ã—ã¦ã©ã®ã‚ˆã†ãªæ€æƒ³ã‚„ç«‹å ´ã‚’æŒã£ã¦ã„ã‚‹ã‹ã‚’ã€200å­—ä»¥å†…ã§ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ï¼š\n\n{combined_text}"

    with st.spinner("ç”ŸæˆAIã§åˆ†æžä¸­..."):
        result = model.generate_content(prompt)
        ai_summary = result.text
        st.subheader("ðŸ§  ç”ŸæˆAIã«ã‚ˆã‚‹åˆ†æžçµæžœ")
        st.write(ai_summary)

    st.subheader("ðŸ“š æ ¹æ‹ ã¨ãªã‚‹ç™ºè¨€æŠœç²‹")
    for s in all_speeches:
        highlighted = s["speech"].replace(keyword, f"**:orange[{keyword}]**")
        meeting_name = s.get("nameOfMeeting") or s.get("meeting") or "ä¸æ˜Ž"
        speaker_name = normalize_name(s["speaker"])
        house = politicians_df.loc[politicians_df["name"] == speaker_name, "house"].values
        house_str = house[0] if len(house) > 0 else "æ‰€å±žé™¢ä¸æ˜Ž"

        st.markdown(f"**{s['speaker']}ï¼ˆ{s['date']}ï¼{house_str}ï¼‰**")
        st.markdown(f"ä¼šè­°åï¼š{meeting_name}")
        st.markdown(f"> {highlighted}")
        st.markdown(f"[ðŸ”— ä¼šè­°éŒ²ã‚’è¦‹ã‚‹]({s['meetingURL']})")
        st.markdown("---")
